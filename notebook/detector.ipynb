{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\subho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2, time, os, tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesFilePath = './coco.names'\n",
    "\n",
    "# modelURL = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\"\n",
    "modelURL = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\"\n",
    "imagePath = \"../../Data/helmet/images/BikesHelmets56.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 92\n"
     ]
    }
   ],
   "source": [
    "with open(classesFilePath, \"r\") as f:\n",
    "    classesList = f.read().splitlines()\n",
    "\n",
    "colorList = np.random.uniform(low=0, high=255, size=(len(classesList), 3))\n",
    "print(len(classesList), len(colorList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading TFOD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName:  efficientdet_d1_coco17_tpu-32.tar.gz ModelName:  efficientdet_d1_coco17_tpu-32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./pretrained_models\\\\models\\\\efficientdet_d1_coco17_tpu-32.tar.gz'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileName = os.path.basename(modelURL)\n",
    "modelName = fileName[:fileName.index('.')]\n",
    "print(\"fileName: \", fileName, \"ModelName: \", modelName)\n",
    "\n",
    "cacheDir = \"./pretrained_models\"\n",
    "# Creating the models directory if not existed before\n",
    "os.makedirs(cacheDir, exist_ok=True)\n",
    "get_file(fileName, origin=modelURL, cache_dir=cacheDir, cache_subdir=\"models\", extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\subho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:277: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.saved_model.load(os.path.join(cacheDir, \"models\", modelName, \"saved_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and converting an image to tensor for test purpose\n",
    "image = cv2.imread(imagePath)\n",
    "imageRGB = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)\n",
    "imageTensor = tf.convert_to_tensor(imageRGB, dtype=tf.uint8)\n",
    "imageTensor = imageTensor[tf.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = model(imageTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBoundingBox(image, detections, threshold = 0.5):\n",
    "    bboxes = detections['detection_boxes'][0].numpy()\n",
    "    classIndexes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "    classScores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "    imH, imW, imC = image.shape\n",
    "    image = cv2.resize(image, (1000, int(imH * (1000/imW))))\n",
    "    imH, imW = (int(imH * (1000/imW)), 1000)\n",
    "\n",
    "    # gives indexes of bboxes with the criteria\n",
    "    bboxIds = tf.image.non_max_suppression(bboxes, classScores, max_output_size=50, iou_threshold=threshold, score_threshold=threshold)\n",
    "\n",
    "\n",
    "    if len(bboxes):\n",
    "        for i in bboxIds:\n",
    "            bbox = tuple(bboxes[i])\n",
    "            classIndex = classIndexes[i]\n",
    "            classLabel = classesList[classIndex]\n",
    "            classConfidence = round(100*classScores[i])\n",
    "            classColor = colorList[classIndex]\n",
    "\n",
    "            displayTxt = f'{classLabel}: {classConfidence}%'\n",
    "            # displayTxt = '{}: {}%'.format(classLabel, classConfidence)\n",
    "            ymin, xmin, ymax, xmax = bbox   # in relative format\n",
    "            ymin, xmin, ymax, xmax = (int(ymin*imH), int(xmin*imW), int(ymax*imH), int(xmax*imW))\n",
    "\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color=classColor, thickness=1)\n",
    "            cv2.putText(image, displayTxt, (xmin, ymin - 7), cv2.FONT_HERSHEY_COMPLEX,  1, classColor, 2)\n",
    "\n",
    "    cv2.imwrite(\"./detections/\" + modelName + \".jpg\", image)\n",
    "    cv2.imshow(\"Object detection\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "createBoundingBox(image, detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdo = cv2.VideoCapture(\"data/v2.mp4\")\n",
    "\n",
    "t1 = 0\n",
    "while True:\n",
    "    captured, frame = vdo.read()\n",
    "\n",
    "    frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if result.detections:\n",
    "        for ids, detection in enumerate(result.detections):\n",
    "            faceDraw.draw_detection(frame, detection)\n",
    "            # print(ids, detection)\n",
    "            print(len(result.detections))\n",
    "\n",
    "\n",
    "    t2 = time.time()\n",
    "    fps = 1/(t2 - t1)\n",
    "    t1 = t2\n",
    "\n",
    "    cv2.putText(frame, f\"FPS: {int(fps)}\", (30, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0, 200, 0), 1)\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.waitKey(0)\n",
    "vdo.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
